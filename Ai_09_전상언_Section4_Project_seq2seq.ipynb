{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UpEon/project_j/blob/main/Ai_09_%EC%A0%84%EC%83%81%EC%96%B8_Section4_Project_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22c2377",
      "metadata": {
        "id": "e22c2377"
      },
      "source": [
        "데이터 구성\n",
        "- sn - 데이터 번호\n",
        "- file_name - 정제된 원본 문서명\n",
        "- data_set - 기술과학/사회과학 구분\n",
        "- domain - 데이터 대분야\n",
        "- subdomain - 데이터 소분야\n",
        "- source - 원문 출처\n",
        "- ko - 한국어 문장\n",
        "- mt - 기계번역 문장\n",
        "- en - 영어 문장\n",
        "- source_language - 원문 언어 코드\n",
        "- target_language - 번역문 언어 코드\n",
        "- license - 라이선스\n",
        "- style - 문체"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdba48b1",
      "metadata": {
        "collapsed": true,
        "id": "bdba48b1",
        "outputId": "2914b6ed-6fd5-4497-b774-931e126b60d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_datasets in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (4.5.2)\n",
            "Requirement already satisfied: six in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.16.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.26.0)\n",
            "Requirement already satisfied: absl-py in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.0.0)\n",
            "Requirement already satisfied: termcolor in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.20.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.62.3)\n",
            "Requirement already satisfied: tensorflow-metadata in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.7.0)\n",
            "Requirement already satisfied: dill in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.3.4)\n",
            "Requirement already satisfied: promise in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.19.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\jeon_sangeon\\anaconda3\\lib\\site-packages (from tqdm->tensorflow_datasets) (0.4.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b822a2",
      "metadata": {
        "id": "81b822a2"
      },
      "outputs": [],
      "source": [
        "# 필요 라이브러리\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import urllib3\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1300e09b",
      "metadata": {
        "id": "1300e09b",
        "outputId": "79f24e0d-e984-4b8e-fcdc-181c39bd4f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1210529, 13) (151316, 13)\n"
          ]
        }
      ],
      "source": [
        "train_csv = '1113_social_train_set_1210529.csv'\n",
        "val_csv = '1113_social_valid_set_151316.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_csv)\n",
        "val_df = pd.read_csv(val_csv)\n",
        "\n",
        "print(train_df.shape, val_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc6e0f0",
      "metadata": {
        "id": "0fc6e0f0"
      },
      "outputs": [],
      "source": [
        "# 데이터 정리\n",
        "train_df = train_df[:10000]\n",
        "val_df = val_df[:4000]\n",
        "\n",
        "train_df = train_df[[\"ko\",\"en\"]]\n",
        "val_df = val_df[[\"ko\",\"en\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64c7d6ad",
      "metadata": {
        "id": "64c7d6ad",
        "outputId": "93d7506d-2c09-4f9a-c796-bfbbcc9ecc4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>제2항을 함께 두는 것이 적절한지에 대하여 논의 과정에서 의문이 제기되기도 하였다.</td>\n",
              "      <td>In the course of the discussion, questions wer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>문제는 거래가 끊어진 경우에는 실제 거래가 이뤄지지 않기 때문에 이러한 실거래가 자...</td>\n",
              "      <td>If the transaction is cut off, the actual tran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>이러한 공공 부문 이동기기 개인 영상정보 규율의 문제점을 개선하기 위해 보호 체계 ...</td>\n",
              "      <td>This discussed ways to improve the protection ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>그 내용은 부품 사업자가 쉽게 알 수 없고 관여할 수 없기 때문에 중간 부품 생산자...</td>\n",
              "      <td>Since the contents are not easily known and in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>매칭정보를 획득하게 되면 통상 ‘ARP spoofing’이라는 해킹기법을 사용한다.</td>\n",
              "      <td>When matching information is obtained, a hacki...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  ko  \\\n",
              "0     제2항을 함께 두는 것이 적절한지에 대하여 논의 과정에서 의문이 제기되기도 하였다.   \n",
              "1  문제는 거래가 끊어진 경우에는 실제 거래가 이뤄지지 않기 때문에 이러한 실거래가 자...   \n",
              "2  이러한 공공 부문 이동기기 개인 영상정보 규율의 문제점을 개선하기 위해 보호 체계 ...   \n",
              "3  그 내용은 부품 사업자가 쉽게 알 수 없고 관여할 수 없기 때문에 중간 부품 생산자...   \n",
              "4     매칭정보를 획득하게 되면 통상 ‘ARP spoofing’이라는 해킹기법을 사용한다.   \n",
              "\n",
              "                                                  en  \n",
              "0  In the course of the discussion, questions wer...  \n",
              "1  If the transaction is cut off, the actual tran...  \n",
              "2  This discussed ways to improve the protection ...  \n",
              "3  Since the contents are not easily known and in...  \n",
              "4  When matching information is obtained, a hacki...  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(train_df))\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14a0e59b",
      "metadata": {
        "id": "14a0e59b",
        "outputId": "86e8f404-f3b0-4b9d-81d7-0b95e09f634e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>국경 없는 인터넷의 특 성을 감안하여, 저작권법의 속지적인 특성에도 불구하고 미국 ...</td>\n",
              "      <td>Considering the type regarding the Internet wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>학습자들이 제시한 건의사항을 해결하기 위해 다음과 같은 논의가 필요하다.</td>\n",
              "      <td>The following discussion is needed to resolve ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011년에 발생한 저축은행 부실사태 이후 관련 연구가 종종 이뤄지고 있다.</td>\n",
              "      <td>Some studies on the period after the savings b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>기업의 성장 측정 방식을 선택함에 있어 기업 규모에 따른 편향적인 결과가 도출되는 ...</td>\n",
              "      <td>In selecting a company's growth measurement me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1인 여행객 중 여성은 52.3%, 남성은 47.7%로 여성이 상대적으로 나 홀로 ...</td>\n",
              "      <td>Among solo travelers, 52.3% were female and 47...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  ko  \\\n",
              "0  국경 없는 인터넷의 특 성을 감안하여, 저작권법의 속지적인 특성에도 불구하고 미국 ...   \n",
              "1           학습자들이 제시한 건의사항을 해결하기 위해 다음과 같은 논의가 필요하다.   \n",
              "2         2011년에 발생한 저축은행 부실사태 이후 관련 연구가 종종 이뤄지고 있다.   \n",
              "3  기업의 성장 측정 방식을 선택함에 있어 기업 규모에 따른 편향적인 결과가 도출되는 ...   \n",
              "4  1인 여행객 중 여성은 52.3%, 남성은 47.7%로 여성이 상대적으로 나 홀로 ...   \n",
              "\n",
              "                                                  en  \n",
              "0  Considering the type regarding the Internet wi...  \n",
              "1  The following discussion is needed to resolve ...  \n",
              "2  Some studies on the period after the savings b...  \n",
              "3  In selecting a company's growth measurement me...  \n",
              "4  Among solo travelers, 52.3% were female and 47...  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(val_df))\n",
        "val_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "524da7f9",
      "metadata": {
        "id": "524da7f9"
      },
      "outputs": [],
      "source": [
        "questions = []\n",
        "for sentence in train_df['ko']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    questions.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3888dc7e",
      "metadata": {
        "id": "3888dc7e"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "for sentence in train_df['en']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    answers.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "256f699d",
      "metadata": {
        "id": "256f699d"
      },
      "outputs": [],
      "source": [
        "questions2 = []\n",
        "for sentence in val_df['ko']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    questions2.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e8a25e",
      "metadata": {
        "id": "89e8a25e"
      },
      "outputs": [],
      "source": [
        "answers2 = []\n",
        "for sentence in val_df['en']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    answers2.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6190714d",
      "metadata": {
        "id": "6190714d",
        "outputId": "37c7ca4a-fb3c-4a73-8b6b-4008827d5d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['제2항을 함께 두는 것이 적절한지에 대하여 논의 과정에서 의문이 제기되기도 하였다 .', '문제는 거래가 끊어진 경우에는 실제 거래가 이뤄지지 않기 때문에 이러한 실거래가 자료조차 찾을 수 없다는 점이다 .', '이러한 공공 부문 이동기기 개인 영상정보 규율의 문제점을 개선하기 위해 보호 체계 및 법제 개선방안을 논의하였다 .', '그 내용은 부품 사업자가 쉽게 알 수 없고 관여할 수 없기 때문에 중간 부품 생산자의 판매 행위는 대단히 불안한 지위에 놓이게 된다 .', '매칭정보를 획득하게 되면 통상 ‘ARP spoofing’이라는 해킹기법을 사용한다 .']\n",
            "['In the course of the discussion ,  questions were raised as to whether it was appropriate to put Paragraph 2 together .', 'If the transaction is cut off ,  the actual transaction price cannot even be found because the actual transaction will not take place .', 'This discussed ways to improve the protection system and legal system in order to improve such a problem of the regulation of personal image information on mobile devices in the public sector .', \"Since the contents are not easily known and involved by the parts business operator ,  intermediate parts manufacturers' sales behavior is placed in a precarious position .\", \"When matching information is obtained ,  a hacking technique called 'ARP spoofing' is usually used .\"]\n"
          ]
        }
      ],
      "source": [
        "print(questions[:5])\n",
        "print(answers[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a1f8f45",
      "metadata": {
        "id": "1a1f8f45"
      },
      "outputs": [],
      "source": [
        "# 서브워드텍스트인코더를 사용하여 질문과 답변을 모두 포함한 단어 집합(Vocabulary) 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**13)\n",
        "\n",
        "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad6c1680",
      "metadata": {
        "id": "ad6c1680"
      },
      "outputs": [],
      "source": [
        "# 서브워드텍스트인코더를 사용하여 질문과 답변을 모두 포함한 단어 집합(Vocabulary) 생성\n",
        "tokenizer2 = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions2 + answers2, target_vocab_size=2**13)\n",
        "\n",
        "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
        "START_TOKEN2, END_TOKEN2 = [tokenizer2.vocab_size], [tokenizer2.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
        "VOCAB_SIZE2 = tokenizer2.vocab_size + 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46f6e612",
      "metadata": {
        "id": "46f6e612",
        "outputId": "01ed3e47-fb1c-470e-c18a-e6f497fda0be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "시작 토큰 번호 : [8094]\n",
            "종료 토큰 번호 : [8095]\n",
            "단어 집합의 크기 : 8096\n"
          ]
        }
      ],
      "source": [
        "print('시작 토큰 번호 :',START_TOKEN)\n",
        "print('종료 토큰 번호 :',END_TOKEN)\n",
        "print('단어 집합의 크기 :',VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "405f90e2",
      "metadata": {
        "id": "405f90e2",
        "outputId": "acdfa63f-760f-4e13-f007-81b622a53902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized sample question: [2372, 3, 151, 5708, 2358, 258, 125, 221, 28, 829, 1345, 2284, 17, 216, 24, 125, 221, 675, 7380, 112, 1]\n"
          ]
        }
      ],
      "source": [
        "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
        "print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62f35f31",
      "metadata": {
        "id": "62f35f31",
        "outputId": "1403af8a-c80b-41f2-f310-164ce255aadd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장 [2372, 3, 151, 5708, 2358, 258, 125, 221, 28, 829, 1345, 2284, 17, 216, 24, 125, 221, 675, 7380, 112, 1]\n",
            "기존 문장: 반면 ,  실적이 예상보다 부진한 기업의 주요 원인은 내수 부진이라고 응답하였다 .\n"
          ]
        }
      ],
      "source": [
        "# 서브워드텍스트인코더 토크나이저의 .encode()와 decode() 테스트해보기\n",
        "\n",
        "# 임의의 입력 문장을 sample_string에 저장\n",
        "sample_string = questions[20]\n",
        "\n",
        "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('기존 문장: {}'.format(original_string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c903c92a",
      "metadata": {
        "id": "c903c92a",
        "outputId": "d97604ad-b48c-4a9a-bf9a-eacef75d1c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2372 ----> 반면\n",
            "3 ---->  ,  \n",
            "151 ----> 실\n",
            "5708 ----> 적이 \n",
            "2358 ----> 예상\n",
            "258 ----> 보다 \n",
            "125 ----> 부\n",
            "221 ----> 진\n",
            "28 ----> 한 \n",
            "829 ----> 기업의 \n",
            "1345 ----> 주요 \n",
            "2284 ----> 원인\n",
            "17 ----> 은 \n",
            "216 ----> 내\n",
            "24 ----> 수 \n",
            "125 ----> 부\n",
            "221 ----> 진\n",
            "675 ----> 이라고 \n",
            "7380 ----> 응답\n",
            "112 ----> 하였다\n",
            "1 ---->  .\n"
          ]
        }
      ],
      "source": [
        "# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n",
        "# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\n",
        "for ts in tokenized_string:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b26b18c",
      "metadata": {
        "id": "1b26b18c"
      },
      "source": [
        "기계 번역기 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c7e760",
      "metadata": {
        "id": "c0c7e760"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aac6c247",
      "metadata": {
        "id": "aac6c247"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "793cc9b9",
      "metadata": {
        "id": "793cc9b9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde625bb",
      "metadata": {
        "id": "bde625bb"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 64\n",
        "hidden_units = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c82770f",
      "metadata": {
        "collapsed": true,
        "id": "3c82770f",
        "outputId": "179c5ab0-5bee-4460-eb39-e50d022d9f0d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'src_vocab_size' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mC:\\Users\\JEON_S~1\\AppData\\Local\\Temp/ipykernel_22720/3552522168.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 인코더\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mencoder_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0menc_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_vocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 임베딩 층\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0menc_masking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMasking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_emb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 패딩 0은 연산에서 제외\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mencoder_lstm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 상태값 리턴을 위해 return_state는 True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'src_vocab_size' is not defined"
          ]
        }
      ],
      "source": [
        "# 인코더\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
        "encoder_lstm = LSTM(hidden_units, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
        "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d7268ca",
      "metadata": {
        "id": "5d7268ca"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss_function, metrics=[accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df50ab4c",
      "metadata": {
        "id": "df50ab4c"
      },
      "outputs": [],
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32b9ea7f",
      "metadata": {
        "id": "32b9ea7f"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "model.fit(dataset, batch_size=64, epochs=EPOCHS, validation_data= dataset_val)\n",
        "print(results.history)\n",
        "\n",
        "# 훈련 과정 시각화 (정확도)\n",
        "plt.plot(results.history['accuracy'])\n",
        "plt.plot(results.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# 훈련 과정 시각화 (손실)\n",
        "plt.plot(results.history['loss'])\n",
        "plt.plot(results.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3fe487",
      "metadata": {
        "id": "ff3fe487"
      },
      "source": [
        "재시도중 시간부족"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea1f0f87",
      "metadata": {
        "id": "ea1f0f87"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "418db8a2",
      "metadata": {
        "id": "418db8a2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b219e1cf",
      "metadata": {
        "id": "b219e1cf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "949eb21a",
      "metadata": {
        "id": "949eb21a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd93a07e",
      "metadata": {
        "id": "cd93a07e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f7feec8",
      "metadata": {
        "id": "6f7feec8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dcc9ec4",
      "metadata": {
        "id": "3dcc9ec4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42b6ab4b",
      "metadata": {
        "id": "42b6ab4b"
      },
      "source": [
        "# 에러 발생한 LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c81a6f57",
      "metadata": {
        "id": "c81a6f57",
        "outputId": "b679ec9d-342a-42dd-c4c6-e19596295fd6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4918</th>\n",
              "      <td>재가입 시점에, 당신은 변경된 보장내용으로 가입하게 되고 사회적, 경제적 상황에 따...</td>\n",
              "      <td>\\tAt the time of re-subscription, you will sub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2041</th>\n",
              "      <td>가족 자본주의\"는 글자 그대로 창출된 이윤을 재투자하여 이윤의 지속적인 축적을 보장...</td>\n",
              "      <td>\\t\"Family capitalism\" literally means the fami...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>본 연구에서는 플립러닝에서 협력적 자기효능감이 학습 성과를 유의하게 예측하는지 살펴...</td>\n",
              "      <td>\\tIn this study, we would like to examine whet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3272</th>\n",
              "      <td>부동산세는 건물 또는 토지에 부과되며 지방자치체 조세수입의 가장 주요한 재원이다.</td>\n",
              "      <td>\\tReal estate taxes are levied on buildings or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9506</th>\n",
              "      <td>경찰도 범죄수사에 관한 준칙을 제정하고 시행하고 있는데, 그것이 바로 범죄수사 규칙이다.</td>\n",
              "      <td>\\tThe police are also enacting and implementin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7802</th>\n",
              "      <td>먼저, 전체 프로그램을 세부적으로 살펴보자면, 두산 인문 극장이라는 주제 아래 3개...</td>\n",
              "      <td>\\tFirst of all, looking at the whole program i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7794</th>\n",
              "      <td>대부분 해금 등 국악 연주자의 시각으로 음악을 분석하거나 무용 이론 및 역사에 대한...</td>\n",
              "      <td>\\tMost of them are focused on analyzing music ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7530</th>\n",
              "      <td>변경 계약의 취소는 명칭 그대로'계약'의 취소에 관한것이지, 변경 계약과 별도로 '...</td>\n",
              "      <td>\\tAs the name of the change contract is cancel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4646</th>\n",
              "      <td>은행거래에 따른 수수료 등의 비용을 줄일 수 있을 것이다.</td>\n",
              "      <td>\\tIt will be possible to reduce the cost of ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4311</th>\n",
              "      <td>오히려 오늘의 설치 미술에서 보듯이, 자기만의 독자적 컨셉으로 승부하는 개념 예술의...</td>\n",
              "      <td>\\tRather, as seen in today's installation art,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     ko  \\\n",
              "4918  재가입 시점에, 당신은 변경된 보장내용으로 가입하게 되고 사회적, 경제적 상황에 따...   \n",
              "2041  가족 자본주의\"는 글자 그대로 창출된 이윤을 재투자하여 이윤의 지속적인 축적을 보장...   \n",
              "1067  본 연구에서는 플립러닝에서 협력적 자기효능감이 학습 성과를 유의하게 예측하는지 살펴...   \n",
              "3272      부동산세는 건물 또는 토지에 부과되며 지방자치체 조세수입의 가장 주요한 재원이다.   \n",
              "9506  경찰도 범죄수사에 관한 준칙을 제정하고 시행하고 있는데, 그것이 바로 범죄수사 규칙이다.   \n",
              "7802  먼저, 전체 프로그램을 세부적으로 살펴보자면, 두산 인문 극장이라는 주제 아래 3개...   \n",
              "7794  대부분 해금 등 국악 연주자의 시각으로 음악을 분석하거나 무용 이론 및 역사에 대한...   \n",
              "7530  변경 계약의 취소는 명칭 그대로'계약'의 취소에 관한것이지, 변경 계약과 별도로 '...   \n",
              "4646                   은행거래에 따른 수수료 등의 비용을 줄일 수 있을 것이다.   \n",
              "4311  오히려 오늘의 설치 미술에서 보듯이, 자기만의 독자적 컨셉으로 승부하는 개념 예술의...   \n",
              "\n",
              "                                                     en  \n",
              "4918  \\tAt the time of re-subscription, you will sub...  \n",
              "2041  \\t\"Family capitalism\" literally means the fami...  \n",
              "1067  \\tIn this study, we would like to examine whet...  \n",
              "3272  \\tReal estate taxes are levied on buildings or...  \n",
              "9506  \\tThe police are also enacting and implementin...  \n",
              "7802  \\tFirst of all, looking at the whole program i...  \n",
              "7794  \\tMost of them are focused on analyzing music ...  \n",
              "7530  \\tAs the name of the change contract is cancel...  \n",
              "4646  \\tIt will be possible to reduce the cost of ba...  \n",
              "4311  \\tRather, as seen in today's installation art,...  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.en = train_df.en.apply(lambda x : '\\t' + x + '\\n')\n",
        "val_df.en = val_df.en.apply(lambda x : '\\t' + x + '\\n')\n",
        "\n",
        "train_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a79cea12",
      "metadata": {
        "id": "a79cea12"
      },
      "outputs": [],
      "source": [
        "# 문자 집합 구축\n",
        "ko_vocab = set()\n",
        "for line in train_df.ko: # 1줄씩 읽음\n",
        "    for char in line: # 1개의 문자씩 읽음\n",
        "        ko_vocab.add(char)\n",
        "\n",
        "en_vocab = set()\n",
        "for line in train_df.en:\n",
        "    for char in line:\n",
        "        en_vocab.add(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2293789b",
      "metadata": {
        "id": "2293789b"
      },
      "outputs": [],
      "source": [
        "# 문자 집합 구축\n",
        "ko_vocab2 = set()\n",
        "for line in val_df.ko: # 1줄씩 읽음\n",
        "    for char in line: # 1개의 문자씩 읽음\n",
        "        ko_vocab2.add(char)\n",
        "\n",
        "en_vocab2 = set()\n",
        "for line in val_df.en:\n",
        "    for char in line:\n",
        "        en_vocab2.add(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37d56c71",
      "metadata": {
        "id": "37d56c71",
        "outputId": "291b459f-6a91-476b-9084-5c886243a113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "source 문장의 char 집합 : 1329\n",
            "target 문장의 char 집합 : 132\n"
          ]
        }
      ],
      "source": [
        "ko_vocab_size = len(ko_vocab)+1\n",
        "en_vocab_size = len(en_vocab)+1\n",
        "print('source 문장의 char 집합 :',ko_vocab_size)\n",
        "print('target 문장의 char 집합 :',en_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e57b0e4",
      "metadata": {
        "collapsed": true,
        "id": "5e57b0e4",
        "outputId": "19ad1150-d300-48ef-91ef-bf36d4a2bfd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n']\n",
            "['L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']\n"
          ]
        }
      ],
      "source": [
        "ko_vocab = sorted(list(ko_vocab))\n",
        "en_vocab = sorted(list(en_vocab))\n",
        "print(ko_vocab[45:75])\n",
        "print(en_vocab[45:75])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73d4e21c",
      "metadata": {
        "collapsed": true,
        "id": "73d4e21c",
        "outputId": "98c96053-3968-45ad-b799-fc227da78c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, '+': 12, ',': 13, '-': 14, '.': 15, '/': 16, '0': 17, '1': 18, '2': 19, '3': 20, '4': 21, '5': 22, '6': 23, '7': 24, '8': 25, '9': 26, ':': 27, '<': 28, '=': 29, '>': 30, '?': 31, 'A': 32, 'B': 33, 'C': 34, 'D': 35, 'E': 36, 'F': 37, 'G': 38, 'H': 39, 'I': 40, 'J': 41, 'K': 42, 'L': 43, 'M': 44, 'N': 45, 'O': 46, 'P': 47, 'Q': 48, 'R': 49, 'S': 50, 'T': 51, 'U': 52, 'V': 53, 'W': 54, 'X': 55, 'Y': 56, 'Z': 57, '[': 58, ']': 59, '_': 60, '`': 61, 'a': 62, 'b': 63, 'c': 64, 'd': 65, 'e': 66, 'f': 67, 'g': 68, 'h': 69, 'i': 70, 'j': 71, 'k': 72, 'l': 73, 'm': 74, 'n': 75, 'o': 76, 'p': 77, 'q': 78, 'r': 79, 's': 80, 't': 81, 'u': 82, 'v': 83, 'w': 84, 'x': 85, 'y': 86, 'z': 87, '~': 88, '£': 89, '°': 90, '·': 91, 'ö': 92, 'ʻ': 93, 'ʼ': 94, 'α': 95, 'π': 96, '–': 97, '—': 98, '‘': 99, '’': 100, '“': 101, '”': 102, '․': 103, '‧': 104, '₂': 105, '⃝': 106, '℃': 107, 'Ⅰ': 108, 'Ⅱ': 109, 'Ⅲ': 110, 'Ⅳ': 111, '→': 112, '∆': 113, '∙': 114, '∼': 115, '≪': 116, '≫': 117, '⋅': 118, '②': 119, '③': 120, '④': 121, '⑤': 122, '△': 123, '♩': 124, '♭': 125, '〈': 126, '〉': 127, '《': 128, '》': 129, '「': 130, '」': 131, '『': 132, '』': 133, '〔': 134, '〕': 135, '〮': 136, 'と': 137, 'ひ': 138, '・': 139, 'ㆍ': 140, '㎡': 141, '下': 142, '丙': 143, '人': 144, '作': 145, '化': 146, '地': 147, '宗': 148, '式': 149, '心': 150, '會': 151, '歌': 152, '祖': 153, '聖': 154, '詩': 155, '長': 156, '靜': 157, '가': 158, '각': 159, '간': 160, '갈': 161, '감': 162, '갑': 163, '값': 164, '갔': 165, '강': 166, '갖': 167, '같': 168, '개': 169, '객': 170, '갠': 171, '갤': 172, '갭': 173, '갯': 174, '갱': 175, '갸': 176, '거': 177, '걱': 178, '건': 179, '걷': 180, '걸': 181, '검': 182, '겁': 183, '것': 184, '겉': 185, '겊': 186, '게': 187, '겐': 188, '겟': 189, '겠': 190, '겨': 191, '격': 192, '겪': 193, '견': 194, '결': 195, '겸': 196, '겹': 197, '겼': 198, '경': 199, '계': 200, '고': 201, '곡': 202, '곤': 203, '곧': 204, '골': 205, '곰': 206, '곱': 207, '곳': 208, '공': 209, '과': 210, '곽': 211, '관': 212, '괄': 213, '괌': 214, '괏': 215, '광': 216, '괜': 217, '괴': 218, '굉': 219, '교': 220, '구': 221, '국': 222, '군': 223, '굳': 224, '굴': 225, '굵': 226, '굶': 227, '굽': 228, '굿': 229, '궁': 230, '권': 231, '궐': 232, '궤': 233, '귀': 234, '규': 235, '균': 236, '그': 237, '극': 238, '근': 239, '글': 240, '금': 241, '급': 242, '긋': 243, '긍': 244, '기': 245, '긴': 246, '길': 247, '김': 248, '깃': 249, '깅': 250, '깊': 251, '까': 252, '깎': 253, '깐': 254, '깔': 255, '깜': 256, '깝': 257, '깥': 258, '깨': 259, '꺼': 260, '꺾': 261, '껄': 262, '껍': 263, '껏': 264, '껑': 265, '께': 266, '껴': 267, '꼈': 268, '꼬': 269, '꼭': 270, '꼴': 271, '꼼': 272, '꼽': 273, '꽁': 274, '꽃': 275, '꽉': 276, '꾀': 277, '꾸': 278, '꾼': 279, '꿀': 280, '꿈': 281, '꿔': 282, '꿰': 283, '뀌': 284, '뀐': 285, '뀔': 286, '끄': 287, '끈': 288, '끊': 289, '끌': 290, '끓': 291, '끔': 292, '끗': 293, '끝': 294, '끼': 295, '낀': 296, '낄': 297, '낌': 298, '나': 299, '낙': 300, '낚': 301, '난': 302, '날': 303, '낡': 304, '남': 305, '납': 306, '낫': 307, '났': 308, '낭': 309, '낮': 310, '낯': 311, '낳': 312, '내': 313, '낸': 314, '낼': 315, '냄': 316, '냇': 317, '냈': 318, '냉': 319, '냐': 320, '냘': 321, '냥': 322, '너': 323, '넉': 324, '넌': 325, '널': 326, '넓': 327, '넘': 328, '넣': 329, '네': 330, '넬': 331, '넷': 332, '녀': 333, '녁': 334, '년': 335, '념': 336, '녔': 337, '녕': 338, '노': 339, '녹': 340, '논': 341, '놀': 342, '놈': 343, '농': 344, '높': 345, '놓': 346, '놨': 347, '뇌': 348, '뇨': 349, '뇰': 350, '누': 351, '눅': 352, '눈': 353, '눌': 354, '눔': 355, '눗': 356, '눠': 357, '뉘': 358, '뉜': 359, '뉠': 360, '뉴': 361, '늄': 362, '느': 363, '늑': 364, '는': 365, '늘': 366, '늙': 367, '늠': 368, '능': 369, '늦': 370, '늪': 371, '늬': 372, '니': 373, '닉': 374, '닌': 375, '닐': 376, '님': 377, '닝': 378, '다': 379, '닥': 380, '단': 381, '닫': 382, '달': 383, '닭': 384, '닮': 385, '담': 386, '답': 387, '당': 388, '닿': 389, '대': 390, '댄': 391, '댐': 392, '댓': 393, '더': 394, '덕': 395, '던': 396, '덜': 397, '덟': 398, '덤': 399, '덧': 400, '덩': 401, '덮': 402, '데': 403, '덴': 404, '델': 405, '뎀': 406, '뎁': 407, '도': 408, '독': 409, '돈': 410, '돋': 411, '돌': 412, '돕': 413, '동': 414, '돼': 415, '됐': 416, '되': 417, '된': 418, '될': 419, '됨': 420, '두': 421, '둑': 422, '둔': 423, '둘': 424, '둠': 425, '둥': 426, '뒤': 427, '뒷': 428, '듀': 429, '듈': 430, '드': 431, '득': 432, '든': 433, '듣': 434, '들': 435, '듦': 436, '듬': 437, '듭': 438, '듯': 439, '등': 440, '디': 441, '딘': 442, '딜': 443, '딤': 444, '딥': 445, '딧': 446, '딩': 447, '딪': 448, '따': 449, '딱': 450, '딴': 451, '딸': 452, '땀': 453, '땅': 454, '때': 455, '떠': 456, '떡': 457, '떤': 458, '떨': 459, '떻': 460, '떼': 461, '또': 462, '똑': 463, '똔': 464, '뚜': 465, '뚝': 466, '뚫': 467, '뚱': 468, '뛰': 469, '뜨': 470, '뜬': 471, '뜯': 472, '뜰': 473, '뜻': 474, '띄': 475, '띈': 476, '띠': 477, '띤': 478, '라': 479, '락': 480, '란': 481, '랄': 482, '람': 483, '랍': 484, '랏': 485, '랐': 486, '랑': 487, '랗': 488, '래': 489, '랙': 490, '랜': 491, '램': 492, '랫': 493, '랬': 494, '랭': 495, '략': 496, '량': 497, '러': 498, '런': 499, '럴': 500, '럼': 501, '럽': 502, '럿': 503, '렀': 504, '렇': 505, '레': 506, '렉': 507, '렌': 508, '렐': 509, '렛': 510, '려': 511, '력': 512, '련': 513, '렬': 514, '렴': 515, '렵': 516, '렷': 517, '렸': 518, '령': 519, '례': 520, '롄': 521, '로': 522, '록': 523, '론': 524, '롤': 525, '롬': 526, '롭': 527, '롯': 528, '롱': 529, '뢰': 530, '룀': 531, '료': 532, '룡': 533, '루': 534, '룩': 535, '룬': 536, '룰': 537, '룸': 538, '룹': 539, '룻': 540, '룽': 541, '뤄': 542, '뤼': 543, '류': 544, '륙': 545, '륜': 546, '률': 547, '륨': 548, '륭': 549, '르': 550, '륵': 551, '른': 552, '를': 553, '름': 554, '릇': 555, '릎': 556, '리': 557, '릭': 558, '린': 559, '릴': 560, '림': 561, '립': 562, '릿': 563, '링': 564, '마': 565, '막': 566, '만': 567, '많': 568, '말': 569, '맑': 570, '맘': 571, '맙': 572, '맛': 573, '망': 574, '맞': 575, '맡': 576, '매': 577, '맥': 578, '맨': 579, '맵': 580, '맷': 581, '맹': 582, '맺': 583, '머': 584, '먹': 585, '먼': 586, '멀': 587, '멈': 588, '멋': 589, '멍': 590, '메': 591, '멕': 592, '멘': 593, '멜': 594, '멧': 595, '멩': 596, '며': 597, '면': 598, '멸': 599, '몄': 600, '명': 601, '몇': 602, '모': 603, '목': 604, '몫': 605, '몬': 606, '몰': 607, '몸': 608, '몹': 609, '못': 610, '몽': 611, '묘': 612, '무': 613, '묵': 614, '묶': 615, '문': 616, '묻': 617, '물': 618, '뭇': 619, '뭉': 620, '뭐': 621, '뭔': 622, '뮈': 623, '뮤': 624, '뮬': 625, '므': 626, '미': 627, '믹': 628, '민': 629, '믿': 630, '밀': 631, '밈': 632, '밋': 633, '밍': 634, '및': 635, '밑': 636, '바': 637, '박': 638, '밖': 639, '반': 640, '받': 641, '발': 642, '밝': 643, '밟': 644, '밤': 645, '밥': 646, '방': 647, '밭': 648, '배': 649, '백': 650, '밴': 651, '뱃': 652, '뱅': 653, '버': 654, '번': 655, '벌': 656, '범': 657, '법': 658, '벗': 659, '벚': 660, '베': 661, '벡': 662, '벤': 663, '벨': 664, '벳': 665, '벼': 666, '벽': 667, '변': 668, '별': 669, '볍': 670, '병': 671, '볜': 672, '보': 673, '복': 674, '본': 675, '볼': 676, '봄': 677, '봅': 678, '봇': 679, '봉': 680, '봐': 681, '봤': 682, '부': 683, '북': 684, '분': 685, '불': 686, '붉': 687, '붓': 688, '붕': 689, '붙': 690, '뷔': 691, '뷰': 692, '브': 693, '븐': 694, '블': 695, '비': 696, '빅': 697, '빈': 698, '빌': 699, '빗': 700, '빙': 701, '빚': 702, '빛': 703, '빠': 704, '빨': 705, '빴': 706, '빵': 707, '빼': 708, '뺀': 709, '뺄': 710, '뻔': 711, '뻗': 712, '뻥': 713, '뼈': 714, '뽕': 715, '뿌': 716, '뿐': 717, '뿔': 718, '뿜': 719, '쁘': 720, '쁜': 721, '쁨': 722, '삐': 723, '사': 724, '삭': 725, '산': 726, '살': 727, '삶': 728, '삼': 729, '삽': 730, '상': 731, '새': 732, '색': 733, '샌': 734, '샐': 735, '샘': 736, '생': 737, '샤': 738, '샬': 739, '샴': 740, '샹': 741, '섀': 742, '서': 743, '석': 744, '섞': 745, '선': 746, '섣': 747, '설': 748, '섬': 749, '섭': 750, '섯': 751, '섰': 752, '성': 753, '세': 754, '섹': 755, '센': 756, '셀': 757, '셈': 758, '셉': 759, '셋': 760, '셍': 761, '셔': 762, '션': 763, '셜': 764, '셨': 765, '셰': 766, '셸': 767, '소': 768, '속': 769, '손': 770, '솔': 771, '송': 772, '쇄': 773, '쇠': 774, '쇤': 775, '쇼': 776, '숍': 777, '수': 778, '숙': 779, '순': 780, '술': 781, '숨': 782, '숫': 783, '숭': 784, '숲': 785, '쉬': 786, '쉽': 787, '슈': 788, '슐': 789, '스': 790, '슨': 791, '슬': 792, '슴': 793, '습': 794, '슷': 795, '승': 796, '시': 797, '식': 798, '신': 799, '싣': 800, '실': 801, '싫': 802, '심': 803, '십': 804, '싱': 805, '싶': 806, '싸': 807, '싹': 808, '싼': 809, '쌀': 810, '쌍': 811, '쌓': 812, '써': 813, '썩': 814, '썼': 815, '쏘': 816, '쏜': 817, '쏟': 818, '쏠': 819, '쓰': 820, '쓴': 821, '쓸': 822, '씁': 823, '씌': 824, '씨': 825, '씩': 826, '씬': 827, '씹': 828, '씻': 829, '아': 830, '악': 831, '안': 832, '앉': 833, '않': 834, '알': 835, '앓': 836, '암': 837, '압': 838, '앗': 839, '았': 840, '앙': 841, '앞': 842, '애': 843, '액': 844, '앤': 845, '앨': 846, '앱': 847, '앵': 848, '야': 849, '약': 850, '얀': 851, '얇': 852, '양': 853, '얘': 854, '어': 855, '억': 856, '언': 857, '얻': 858, '얼': 859, '얽': 860, '엄': 861, '업': 862, '없': 863, '엇': 864, '었': 865, '엉': 866, '에': 867, '엑': 868, '엔': 869, '엘': 870, '엠': 871, '여': 872, '역': 873, '연': 874, '열': 875, '염': 876, '엽': 877, '엿': 878, '였': 879, '영': 880, '옆': 881, '예': 882, '옌': 883, '옛': 884, '오': 885, '옥': 886, '온': 887, '올': 888, '옮': 889, '옳': 890, '옴': 891, '옵': 892, '옷': 893, '옹': 894, '와': 895, '완': 896, '왈': 897, '왑': 898, '왔': 899, '왕': 900, '왜': 901, '외': 902, '왼': 903, '요': 904, '욕': 905, '용': 906, '우': 907, '욱': 908, '운': 909, '울': 910, '움': 911, '웃': 912, '웅': 913, '워': 914, '원': 915, '월': 916, '웠': 917, '웨': 918, '웬': 919, '웰': 920, '웸': 921, '웹': 922, '위': 923, '윈': 924, '윌': 925, '윗': 926, '유': 927, '육': 928, '윤': 929, '율': 930, '윳': 931, '융': 932, '으': 933, '은': 934, '을': 935, '읊': 936, '음': 937, '읍': 938, '응': 939, '의': 940, '이': 941, '익': 942, '인': 943, '일': 944, '읽': 945, '잃': 946, '임': 947, '입': 948, '잇': 949, '있': 950, '잉': 951, '잊': 952, '잎': 953, '자': 954, '작': 955, '잔': 956, '잘': 957, '잠': 958, '잡': 959, '잣': 960, '장': 961, '잦': 962, '재': 963, '잭': 964, '쟁': 965, '저': 966, '적': 967, '전': 968, '절': 969, '젊': 970, '점': 971, '접': 972, '정': 973, '젖': 974, '제': 975, '젝': 976, '젠': 977, '젤': 978, '져': 979, '졌': 980, '조': 981, '족': 982, '존': 983, '졸': 984, '좀': 985, '좁': 986, '종': 987, '좇': 988, '좋': 989, '좌': 990, '죄': 991, '죠': 992, '죡': 993, '주': 994, '죽': 995, '준': 996, '줄': 997, '줌': 998, '중': 999, '줘': 1000, '줬': 1001, '쥐': 1002, '쥘': 1003, '즈': 1004, '즉': 1005, '즌': 1006, '즐': 1007, '즘': 1008, '즙': 1009, '증': 1010, '지': 1011, '직': 1012, '진': 1013, '질': 1014, '짐': 1015, '집': 1016, '짓': 1017, '징': 1018, '짚': 1019, '짜': 1020, '짝': 1021, '짢': 1022, '짧': 1023, '짬': 1024, '째': 1025, '쨌': 1026, '쩌': 1027, '쩍': 1028, '쩔': 1029, '쪼': 1030, '쪽': 1031, '쫓': 1032, '쯔': 1033, '쯤': 1034, '찌': 1035, '찍': 1036, '찢': 1037, '찧': 1038, '차': 1039, '착': 1040, '찬': 1041, '찮': 1042, '찰': 1043, '참': 1044, '창': 1045, '찾': 1046, '채': 1047, '책': 1048, '챕': 1049, '챗': 1050, '처': 1051, '척': 1052, '천': 1053, '철': 1054, '첨': 1055, '첩': 1056, '첫': 1057, '청': 1058, '체': 1059, '첼': 1060, '쳄': 1061, '쳐': 1062, '쳤': 1063, '초': 1064, '촉': 1065, '촌': 1066, '촐': 1067, '촛': 1068, '총': 1069, '촬': 1070, '최': 1071, '추': 1072, '축': 1073, '춘': 1074, '출': 1075, '춤': 1076, '춥': 1077, '충': 1078, '춰': 1079, '췄': 1080, '취': 1081, '츠': 1082, '측': 1083, '츰': 1084, '층': 1085, '치': 1086, '칙': 1087, '친': 1088, '칠': 1089, '침': 1090, '칩': 1091, '칫': 1092, '칭': 1093, '카': 1094, '칸': 1095, '칼': 1096, '캄': 1097, '캐': 1098, '캔': 1099, '캘': 1100, '캠': 1101, '캡': 1102, '캥': 1103, '커': 1104, '컨': 1105, '컫': 1106, '컬': 1107, '컴': 1108, '컵': 1109, '컷': 1110, '컸': 1111, '케': 1112, '켈': 1113, '켓': 1114, '켜': 1115, '켰': 1116, '코': 1117, '콕': 1118, '콘': 1119, '콜': 1120, '콤': 1121, '콥': 1122, '콩': 1123, '쾌': 1124, '쿄': 1125, '쿠': 1126, '쿤': 1127, '쿨': 1128, '쿼': 1129, '퀀': 1130, '퀄': 1131, '퀘': 1132, '퀴': 1133, '퀸': 1134, '퀼': 1135, '큐': 1136, '큘': 1137, '크': 1138, '큰': 1139, '클': 1140, '큼': 1141, '키': 1142, '킨': 1143, '킬': 1144, '킴': 1145, '킹': 1146, '타': 1147, '탁': 1148, '탄': 1149, '탈': 1150, '탐': 1151, '탑': 1152, '탓': 1153, '탕': 1154, '태': 1155, '택': 1156, '탤': 1157, '탯': 1158, '탱': 1159, '터': 1160, '턴': 1161, '털': 1162, '텀': 1163, '텄': 1164, '테': 1165, '텍': 1166, '텐': 1167, '텔': 1168, '템': 1169, '텝': 1170, '톈': 1171, '토': 1172, '톡': 1173, '톤': 1174, '톨': 1175, '톱': 1176, '통': 1177, '퇴': 1178, '투': 1179, '툰': 1180, '툴': 1181, '툼': 1182, '튀': 1183, '튜': 1184, '트': 1185, '특': 1186, '튼': 1187, '튿': 1188, '틀': 1189, '틈': 1190, '티': 1191, '틱': 1192, '틴': 1193, '틸': 1194, '팀': 1195, '팅': 1196, '파': 1197, '팎': 1198, '판': 1199, '팔': 1200, '팝': 1201, '패': 1202, '팩': 1203, '팬': 1204, '팸': 1205, '팽': 1206, '퍼': 1207, '펀': 1208, '펄': 1209, '펌': 1210, '페': 1211, '펙': 1212, '펜': 1213, '펠': 1214, '펫': 1215, '펴': 1216, '편': 1217, '펼': 1218, '폈': 1219, '평': 1220, '폐': 1221, '포': 1222, '폭': 1223, '폰': 1224, '폴': 1225, '폼': 1226, '표': 1227, '푯': 1228, '푸': 1229, '푼': 1230, '풀': 1231, '품': 1232, '풋': 1233, '풍': 1234, '퓨': 1235, '프': 1236, '픈': 1237, '플': 1238, '픔': 1239, '피': 1240, '픽': 1241, '핀': 1242, '필': 1243, '핍': 1244, '핏': 1245, '핑': 1246, '하': 1247, '학': 1248, '한': 1249, '할': 1250, '함': 1251, '합': 1252, '항': 1253, '해': 1254, '핵': 1255, '햇': 1256, '했': 1257, '행': 1258, '향': 1259, '허': 1260, '헌': 1261, '헐': 1262, '험': 1263, '헙': 1264, '헝': 1265, '헤': 1266, '헨': 1267, '헬': 1268, '혀': 1269, '혁': 1270, '현': 1271, '혈': 1272, '혐': 1273, '협': 1274, '혔': 1275, '형': 1276, '혜': 1277, '호': 1278, '혹': 1279, '혼': 1280, '홀': 1281, '홈': 1282, '홉': 1283, '홍': 1284, '홑': 1285, '화': 1286, '확': 1287, '환': 1288, '활': 1289, '황': 1290, '횃': 1291, '회': 1292, '획': 1293, '횟': 1294, '횡': 1295, '효': 1296, '후': 1297, '훈': 1298, '훌': 1299, '훔': 1300, '훗': 1301, '훨': 1302, '훼': 1303, '휘': 1304, '휠': 1305, '휴': 1306, '흉': 1307, '흐': 1308, '흑': 1309, '흔': 1310, '흘': 1311, '흠': 1312, '흡': 1313, '흥': 1314, '흩': 1315, '희': 1316, '흰': 1317, '히': 1318, '힉': 1319, '힌': 1320, '힐': 1321, '힘': 1322, '\\ue018': 1323, '３': 1324, '＜': 1325, '＞': 1326, '～': 1327, '･': 1328}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '#': 6, '$': 7, '%': 8, '&': 9, \"'\": 10, '(': 11, ')': 12, '*': 13, '+': 14, ',': 15, '-': 16, '.': 17, '/': 18, '0': 19, '1': 20, '2': 21, '3': 22, '4': 23, '5': 24, '6': 25, '7': 26, '8': 27, '9': 28, ':': 29, ';': 30, '<': 31, '=': 32, '>': 33, '?': 34, 'A': 35, 'B': 36, 'C': 37, 'D': 38, 'E': 39, 'F': 40, 'G': 41, 'H': 42, 'I': 43, 'J': 44, 'K': 45, 'L': 46, 'M': 47, 'N': 48, 'O': 49, 'P': 50, 'Q': 51, 'R': 52, 'S': 53, 'T': 54, 'U': 55, 'V': 56, 'W': 57, 'X': 58, 'Y': 59, 'Z': 60, '[': 61, ']': 62, '_': 63, '`': 64, 'a': 65, 'b': 66, 'c': 67, 'd': 68, 'e': 69, 'f': 70, 'g': 71, 'h': 72, 'i': 73, 'j': 74, 'k': 75, 'l': 76, 'm': 77, 'n': 78, 'o': 79, 'p': 80, 'q': 81, 'r': 82, 's': 83, 't': 84, 'u': 85, 'v': 86, 'w': 87, 'x': 88, 'y': 89, 'z': 90, '~': 91, '£': 92, '°': 93, '·': 94, 'è': 95, 'é': 96, 'ï': 97, 'ó': 98, 'ö': 99, 'ü': 100, 'α': 101, 'π': 102, '–': 103, '—': 104, '‘': 105, '’': 106, '“': 107, '”': 108, '₂': 109, '⃝': 110, '℃': 111, 'Ⅲ': 112, '→': 113, '∆': 114, '②': 115, '③': 116, '④': 117, '⑤': 118, '△': 119, '♩': 120, '♭': 121, '《': 122, '》': 123, '『': 124, '』': 125, 'と': 126, 'ひ': 127, '丙': 128, '\\ue018': 129, 'ﬁ': 130, '･': 131}\n"
          ]
        }
      ],
      "source": [
        "ko_to_index = dict([(word, i+1) for i, word in enumerate(ko_vocab)])\n",
        "en_to_index = dict([(word, i+1) for i, word in enumerate(en_vocab)])\n",
        "print(ko_to_index)\n",
        "print(en_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6213d16",
      "metadata": {
        "id": "a6213d16",
        "outputId": "fd59e8c1-06b5-4d90-d3b8-7aab2b574b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "source 문장의 정수 인코딩 : [[975, 19, 1253, 935, 1, 1251, 266, 1, 421, 365, 1, 184, 941, 1, 967, 969, 1249, 1011, 867, 1, 390, 1247, 872, 1, 341, 940, 1, 210, 973, 867, 743, 1, 940, 616, 941, 1, 975, 245, 417, 245, 408, 1, 1247, 879, 379, 15], [616, 975, 365, 1, 177, 489, 158, 1, 289, 855, 1013, 1, 199, 907, 867, 365, 1, 801, 975, 1, 177, 489, 158, 1, 941, 542, 1011, 1011, 1, 834, 245, 1, 455, 616, 867, 1, 941, 498, 1249, 1, 801, 177, 489, 158, 1, 954, 532, 981, 1039, 1, 1046, 935, 1, 778, 1, 863, 379, 365, 1, 971, 941, 379, 15], [941, 498, 1249, 1, 209, 209, 1, 683, 616, 1, 941, 414, 245, 245, 1, 169, 943, 1, 880, 731, 973, 673, 1, 235, 930, 940, 1, 616, 975, 971, 935, 1, 169, 746, 1247, 245, 1, 923, 1254, 1, 673, 1278, 1, 1059, 200, 1, 635, 1, 658, 975, 1, 169, 746, 647, 832, 935, 1, 341, 940, 1247, 879, 379, 15], [237, 1, 313, 906, 934, 1, 683, 1232, 1, 724, 862, 954, 158, 1, 787, 187, 1, 835, 1, 778, 1, 863, 201, 1, 212, 872, 1250, 1, 778, 1, 863, 245, 1, 455, 616, 867, 1, 999, 160, 1, 683, 1232, 1, 737, 726, 954, 940, 1, 1199, 577, 1, 1258, 923, 365, 1, 390, 381, 1318, 1, 686, 832, 1249, 1, 1011, 923, 867, 1, 346, 941, 187, 1, 418, 379, 15], [577, 1093, 973, 673, 553, 1, 1293, 432, 1247, 187, 1, 417, 598, 1, 1177, 731, 1, 99, 32, 49, 47, 1, 80, 77, 76, 76, 67, 70, 75, 68, 100, 941, 479, 365, 1, 1254, 1146, 245, 658, 935, 1, 724, 906, 1249, 379, 15]]\n"
          ]
        }
      ],
      "source": [
        "encoder_input = []\n",
        "\n",
        "# 1개의 문장\n",
        "for line in train_df.ko:\n",
        "  encoded_line = []\n",
        "  # 각 줄에서 1개의 char\n",
        "  for char in line:\n",
        "    # 각 char을 정수로 변환\n",
        "    encoded_line.append(ko_to_index[char])\n",
        "  encoder_input.append(encoded_line)\n",
        "print('source 문장의 정수 인코딩 :',encoder_input[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35ecaf0d",
      "metadata": {
        "id": "35ecaf0d",
        "outputId": "0a3a9889-07da-4c9b-9097-540a0259f50b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target 문장의 정수 인코딩 : [[1, 43, 78, 3, 84, 72, 69, 3, 67, 79, 85, 82, 83, 69, 3, 79, 70, 3, 84, 72, 69, 3, 68, 73, 83, 67, 85, 83, 83, 73, 79, 78, 15, 3, 81, 85, 69, 83, 84, 73, 79, 78, 83, 3, 87, 69, 82, 69, 3, 82, 65, 73, 83, 69, 68, 3, 65, 83, 3, 84, 79, 3, 87, 72, 69, 84, 72, 69, 82, 3, 73, 84, 3, 87, 65, 83, 3, 65, 80, 80, 82, 79, 80, 82, 73, 65, 84, 69, 3, 84, 79, 3, 80, 85, 84, 3, 50, 65, 82, 65, 71, 82, 65, 80, 72, 3, 21, 3, 84, 79, 71, 69, 84, 72, 69, 82, 17, 2], [1, 43, 70, 3, 84, 72, 69, 3, 84, 82, 65, 78, 83, 65, 67, 84, 73, 79, 78, 3, 73, 83, 3, 67, 85, 84, 3, 79, 70, 70, 15, 3, 84, 72, 69, 3, 65, 67, 84, 85, 65, 76, 3, 84, 82, 65, 78, 83, 65, 67, 84, 73, 79, 78, 3, 80, 82, 73, 67, 69, 3, 67, 65, 78, 78, 79, 84, 3, 69, 86, 69, 78, 3, 66, 69, 3, 70, 79, 85, 78, 68, 3, 66, 69, 67, 65, 85, 83, 69, 3, 84, 72, 69, 3, 65, 67, 84, 85, 65, 76, 3, 84, 82, 65, 78, 83, 65, 67, 84, 73, 79, 78, 3, 87, 73, 76, 76, 3, 78, 79, 84, 3, 84, 65, 75, 69, 3, 80, 76, 65, 67, 69, 17, 2], [1, 54, 72, 73, 83, 3, 68, 73, 83, 67, 85, 83, 83, 69, 68, 3, 87, 65, 89, 83, 3, 84, 79, 3, 73, 77, 80, 82, 79, 86, 69, 3, 84, 72, 69, 3, 80, 82, 79, 84, 69, 67, 84, 73, 79, 78, 3, 83, 89, 83, 84, 69, 77, 3, 65, 78, 68, 3, 76, 69, 71, 65, 76, 3, 83, 89, 83, 84, 69, 77, 3, 73, 78, 3, 79, 82, 68, 69, 82, 3, 84, 79, 3, 73, 77, 80, 82, 79, 86, 69, 3, 83, 85, 67, 72, 3, 65, 3, 80, 82, 79, 66, 76, 69, 77, 3, 79, 70, 3, 84, 72, 69, 3, 82, 69, 71, 85, 76, 65, 84, 73, 79, 78, 3, 79, 70, 3, 80, 69, 82, 83, 79, 78, 65, 76, 3, 73, 77, 65, 71, 69, 3, 73, 78, 70, 79, 82, 77, 65, 84, 73, 79, 78, 3, 79, 78, 3, 77, 79, 66, 73, 76, 69, 3, 68, 69, 86, 73, 67, 69, 83, 3, 73, 78, 3, 84, 72, 69, 3, 80, 85, 66, 76, 73, 67, 3, 83, 69, 67, 84, 79, 82, 17, 2], [1, 53, 73, 78, 67, 69, 3, 84, 72, 69, 3, 67, 79, 78, 84, 69, 78, 84, 83, 3, 65, 82, 69, 3, 78, 79, 84, 3, 69, 65, 83, 73, 76, 89, 3, 75, 78, 79, 87, 78, 3, 65, 78, 68, 3, 73, 78, 86, 79, 76, 86, 69, 68, 3, 66, 89, 3, 84, 72, 69, 3, 80, 65, 82, 84, 83, 3, 66, 85, 83, 73, 78, 69, 83, 83, 3, 79, 80, 69, 82, 65, 84, 79, 82, 15, 3, 73, 78, 84, 69, 82, 77, 69, 68, 73, 65, 84, 69, 3, 80, 65, 82, 84, 83, 3, 77, 65, 78, 85, 70, 65, 67, 84, 85, 82, 69, 82, 83, 10, 3, 83, 65, 76, 69, 83, 3, 66, 69, 72, 65, 86, 73, 79, 82, 3, 73, 83, 3, 80, 76, 65, 67, 69, 68, 3, 73, 78, 3, 65, 3, 80, 82, 69, 67, 65, 82, 73, 79, 85, 83, 3, 80, 79, 83, 73, 84, 73, 79, 78, 17, 2], [1, 57, 72, 69, 78, 3, 77, 65, 84, 67, 72, 73, 78, 71, 3, 73, 78, 70, 79, 82, 77, 65, 84, 73, 79, 78, 3, 73, 83, 3, 79, 66, 84, 65, 73, 78, 69, 68, 15, 3, 65, 3, 72, 65, 67, 75, 73, 78, 71, 3, 84, 69, 67, 72, 78, 73, 81, 85, 69, 3, 67, 65, 76, 76, 69, 68, 3, 10, 35, 52, 50, 3, 83, 80, 79, 79, 70, 73, 78, 71, 10, 3, 73, 83, 3, 85, 83, 85, 65, 76, 76, 89, 3, 85, 83, 69, 68, 17, 2]]\n"
          ]
        }
      ],
      "source": [
        "decoder_input = []\n",
        "for line in train_df.en:\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    encoded_line.append(en_to_index[char])\n",
        "  decoder_input.append(encoded_line)\n",
        "print('target 문장의 정수 인코딩 :',decoder_input[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176ed31a",
      "metadata": {
        "id": "176ed31a",
        "outputId": "6cf8b484-9a55-4a49-8f27-db20f1c4c0fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target 문장 레이블의 정수 인코딩 : [[43, 78, 3, 84, 72, 69, 3, 67, 79, 85, 82, 83, 69, 3, 79, 70, 3, 84, 72, 69, 3, 68, 73, 83, 67, 85, 83, 83, 73, 79, 78, 15, 3, 81, 85, 69, 83, 84, 73, 79, 78, 83, 3, 87, 69, 82, 69, 3, 82, 65, 73, 83, 69, 68, 3, 65, 83, 3, 84, 79, 3, 87, 72, 69, 84, 72, 69, 82, 3, 73, 84, 3, 87, 65, 83, 3, 65, 80, 80, 82, 79, 80, 82, 73, 65, 84, 69, 3, 84, 79, 3, 80, 85, 84, 3, 50, 65, 82, 65, 71, 82, 65, 80, 72, 3, 21, 3, 84, 79, 71, 69, 84, 72, 69, 82, 17, 2], [43, 70, 3, 84, 72, 69, 3, 84, 82, 65, 78, 83, 65, 67, 84, 73, 79, 78, 3, 73, 83, 3, 67, 85, 84, 3, 79, 70, 70, 15, 3, 84, 72, 69, 3, 65, 67, 84, 85, 65, 76, 3, 84, 82, 65, 78, 83, 65, 67, 84, 73, 79, 78, 3, 80, 82, 73, 67, 69, 3, 67, 65, 78, 78, 79, 84, 3, 69, 86, 69, 78, 3, 66, 69, 3, 70, 79, 85, 78, 68, 3, 66, 69, 67, 65, 85, 83, 69, 3, 84, 72, 69, 3, 65, 67, 84, 85, 65, 76, 3, 84, 82, 65, 78, 83, 65, 67, 84, 73, 79, 78, 3, 87, 73, 76, 76, 3, 78, 79, 84, 3, 84, 65, 75, 69, 3, 80, 76, 65, 67, 69, 17, 2], [54, 72, 73, 83, 3, 68, 73, 83, 67, 85, 83, 83, 69, 68, 3, 87, 65, 89, 83, 3, 84, 79, 3, 73, 77, 80, 82, 79, 86, 69, 3, 84, 72, 69, 3, 80, 82, 79, 84, 69, 67, 84, 73, 79, 78, 3, 83, 89, 83, 84, 69, 77, 3, 65, 78, 68, 3, 76, 69, 71, 65, 76, 3, 83, 89, 83, 84, 69, 77, 3, 73, 78, 3, 79, 82, 68, 69, 82, 3, 84, 79, 3, 73, 77, 80, 82, 79, 86, 69, 3, 83, 85, 67, 72, 3, 65, 3, 80, 82, 79, 66, 76, 69, 77, 3, 79, 70, 3, 84, 72, 69, 3, 82, 69, 71, 85, 76, 65, 84, 73, 79, 78, 3, 79, 70, 3, 80, 69, 82, 83, 79, 78, 65, 76, 3, 73, 77, 65, 71, 69, 3, 73, 78, 70, 79, 82, 77, 65, 84, 73, 79, 78, 3, 79, 78, 3, 77, 79, 66, 73, 76, 69, 3, 68, 69, 86, 73, 67, 69, 83, 3, 73, 78, 3, 84, 72, 69, 3, 80, 85, 66, 76, 73, 67, 3, 83, 69, 67, 84, 79, 82, 17, 2], [53, 73, 78, 67, 69, 3, 84, 72, 69, 3, 67, 79, 78, 84, 69, 78, 84, 83, 3, 65, 82, 69, 3, 78, 79, 84, 3, 69, 65, 83, 73, 76, 89, 3, 75, 78, 79, 87, 78, 3, 65, 78, 68, 3, 73, 78, 86, 79, 76, 86, 69, 68, 3, 66, 89, 3, 84, 72, 69, 3, 80, 65, 82, 84, 83, 3, 66, 85, 83, 73, 78, 69, 83, 83, 3, 79, 80, 69, 82, 65, 84, 79, 82, 15, 3, 73, 78, 84, 69, 82, 77, 69, 68, 73, 65, 84, 69, 3, 80, 65, 82, 84, 83, 3, 77, 65, 78, 85, 70, 65, 67, 84, 85, 82, 69, 82, 83, 10, 3, 83, 65, 76, 69, 83, 3, 66, 69, 72, 65, 86, 73, 79, 82, 3, 73, 83, 3, 80, 76, 65, 67, 69, 68, 3, 73, 78, 3, 65, 3, 80, 82, 69, 67, 65, 82, 73, 79, 85, 83, 3, 80, 79, 83, 73, 84, 73, 79, 78, 17, 2], [57, 72, 69, 78, 3, 77, 65, 84, 67, 72, 73, 78, 71, 3, 73, 78, 70, 79, 82, 77, 65, 84, 73, 79, 78, 3, 73, 83, 3, 79, 66, 84, 65, 73, 78, 69, 68, 15, 3, 65, 3, 72, 65, 67, 75, 73, 78, 71, 3, 84, 69, 67, 72, 78, 73, 81, 85, 69, 3, 67, 65, 76, 76, 69, 68, 3, 10, 35, 52, 50, 3, 83, 80, 79, 79, 70, 73, 78, 71, 10, 3, 73, 83, 3, 85, 83, 85, 65, 76, 76, 89, 3, 85, 83, 69, 68, 17, 2]]\n"
          ]
        }
      ],
      "source": [
        "decoder_target = []\n",
        "for line in train_df.en:\n",
        "  timestep = 0\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    if timestep > 0:\n",
        "      encoded_line.append(en_to_index[char])\n",
        "    timestep = timestep + 1\n",
        "  decoder_target.append(encoded_line)\n",
        "print('target 문장 레이블의 정수 인코딩 :',decoder_target[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316179d6",
      "metadata": {
        "id": "316179d6",
        "outputId": "50cfb0f4-e46e-4141-a6d8-12db050b0c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "source 문장의 최대 길이 : 192\n",
            "target 문장의 최대 길이 : 463\n"
          ]
        }
      ],
      "source": [
        "max_ko_len = max([len(line) for line in train_df.ko])\n",
        "max_en_len = max([len(line) for line in train_df.en])\n",
        "print('source 문장의 최대 길이 :',max_ko_len)\n",
        "print('target 문장의 최대 길이 :',max_en_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e36cddf0",
      "metadata": {
        "id": "e36cddf0"
      },
      "outputs": [],
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_ko_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_en_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_en_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b33546d",
      "metadata": {
        "id": "6b33546d"
      },
      "outputs": [],
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e37371",
      "metadata": {
        "id": "24e37371"
      },
      "source": [
        "### seq2seq 기계 번역기 훈련시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5bc139e",
      "metadata": {
        "id": "b5bc139e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab5401f",
      "metadata": {
        "id": "6ab5401f"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = Input(shape=(None, ko_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "\n",
        "# encoder_outputs은 여기서는 불필요\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 은닉 상태와 셀 상태.\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53d18f3c",
      "metadata": {
        "id": "53d18f3c"
      },
      "outputs": [],
      "source": [
        "decoder_inputs = Input(shape=(None, en_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "\n",
        "# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달.\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "decoder_softmax_layer = Dense(en_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "408d9bc2",
      "metadata": {
        "id": "408d9bc2",
        "outputId": "26a1f0c1-4ff7-4234-a993-45c60135aefa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "250/250 [==============================] - 1121s 4s/step - loss: 1.1717 - val_loss: 0.8423\n",
            "Epoch 2/40\n",
            "250/250 [==============================] - 1112s 4s/step - loss: 0.7346 - val_loss: 0.6631\n",
            "Epoch 3/40\n",
            "250/250 [==============================] - 1169s 5s/step - loss: 0.6234 - val_loss: 0.5827\n",
            "Epoch 4/40\n",
            "250/250 [==============================] - 1164s 5s/step - loss: 0.5519 - val_loss: 0.5219\n",
            "Epoch 5/40\n",
            "250/250 [==============================] - 1177s 5s/step - loss: 0.4988 - val_loss: 0.4776\n",
            "Epoch 6/40\n",
            "250/250 [==============================] - 1158s 5s/step - loss: 0.4602 - val_loss: 0.4476\n",
            "Epoch 7/40\n",
            "250/250 [==============================] - 1144s 5s/step - loss: 0.4322 - val_loss: 0.4226\n",
            "Epoch 8/40\n",
            "250/250 [==============================] - 1137s 5s/step - loss: 0.4112 - val_loss: 0.4059\n",
            "Epoch 9/40\n",
            "250/250 [==============================] - 1140s 5s/step - loss: 0.3950 - val_loss: 0.3939\n",
            "Epoch 10/40\n",
            "250/250 [==============================] - 1135s 5s/step - loss: 0.3824 - val_loss: 0.3828\n",
            "Epoch 11/40\n",
            "250/250 [==============================] - 1146s 5s/step - loss: 0.3722 - val_loss: 0.3751\n",
            "Epoch 12/40\n",
            "250/250 [==============================] - 1130s 5s/step - loss: 0.3639 - val_loss: 0.3682\n",
            "Epoch 13/40\n",
            "250/250 [==============================] - 1131s 5s/step - loss: 0.3569 - val_loss: 0.3619\n",
            "Epoch 14/40\n",
            "250/250 [==============================] - 1158s 5s/step - loss: 0.3509 - val_loss: 0.3570\n",
            "Epoch 15/40\n",
            "250/250 [==============================] - 1148s 5s/step - loss: 0.3458 - val_loss: 0.3538\n",
            "Epoch 16/40\n",
            "250/250 [==============================] - 1160s 5s/step - loss: 0.3412 - val_loss: 0.3502\n",
            "Epoch 17/40\n",
            "250/250 [==============================] - 1149s 5s/step - loss: 0.3372 - val_loss: 0.3466\n",
            "Epoch 18/40\n",
            "250/250 [==============================] - 735s 3s/step - loss: 0.3356 - val_loss: 0.3463\n",
            "Epoch 19/40\n",
            "250/250 [==============================] - 690s 3s/step - loss: 0.3325 - val_loss: 0.3452\n",
            "Epoch 20/40\n",
            "250/250 [==============================] - 685s 3s/step - loss: 0.3291 - val_loss: 0.3421\n",
            "Epoch 21/40\n",
            "250/250 [==============================] - 676s 3s/step - loss: 0.3263 - val_loss: 0.3402\n",
            "Epoch 22/40\n",
            "250/250 [==============================] - 683s 3s/step - loss: 0.3237 - val_loss: 0.3386\n",
            "Epoch 23/40\n",
            "250/250 [==============================] - 683s 3s/step - loss: 0.3213 - val_loss: 0.3372\n",
            "Epoch 24/40\n",
            "250/250 [==============================] - 674s 3s/step - loss: 0.3190 - val_loss: 0.3358\n",
            "Epoch 25/40\n",
            "250/250 [==============================] - 678s 3s/step - loss: 0.3170 - val_loss: 0.3353\n",
            "Epoch 26/40\n",
            "250/250 [==============================] - 685s 3s/step - loss: 0.3150 - val_loss: 0.3337\n",
            "Epoch 27/40\n",
            "250/250 [==============================] - 686s 3s/step - loss: 0.3133 - val_loss: 0.3323\n",
            "Epoch 28/40\n",
            "250/250 [==============================] - 687s 3s/step - loss: 0.3115 - val_loss: 0.3325\n",
            "Epoch 29/40\n",
            "250/250 [==============================] - 688s 3s/step - loss: 0.3099 - val_loss: 0.3310\n",
            "Epoch 30/40\n",
            "250/250 [==============================] - 691s 3s/step - loss: 0.3084 - val_loss: 0.3302\n",
            "Epoch 31/40\n",
            "250/250 [==============================] - 689s 3s/step - loss: 0.3070 - val_loss: 0.3303\n",
            "Epoch 32/40\n",
            "250/250 [==============================] - 685s 3s/step - loss: 0.3056 - val_loss: 0.3300\n",
            "Epoch 33/40\n",
            "250/250 [==============================] - 685s 3s/step - loss: 0.3043 - val_loss: 0.3286\n",
            "Epoch 34/40\n",
            "250/250 [==============================] - 689s 3s/step - loss: 0.3031 - val_loss: 0.3292\n",
            "Epoch 35/40\n",
            "250/250 [==============================] - 691s 3s/step - loss: 0.3019 - val_loss: 0.3285\n",
            "Epoch 36/40\n",
            "250/250 [==============================] - 685s 3s/step - loss: 0.3007 - val_loss: 0.3285\n",
            "Epoch 37/40\n",
            "250/250 [==============================] - 701s 3s/step - loss: 0.2996 - val_loss: 0.3279\n",
            "Epoch 38/40\n",
            "250/250 [==============================] - 701s 3s/step - loss: 0.2985 - val_loss: 0.3273\n",
            "Epoch 39/40\n",
            "250/250 [==============================] - 695s 3s/step - loss: 0.2975 - val_loss: 0.3281\n",
            "Epoch 40/40\n",
            "250/250 [==============================] - 699s 3s/step - loss: 0.2965 - val_loss: 0.3273\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x202da1fa9d0>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=30, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2370efb9",
      "metadata": {
        "id": "2370efb9"
      },
      "source": [
        "### seq2seq 기계 번역기 동작시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cc63275",
      "metadata": {
        "id": "9cc63275"
      },
      "outputs": [],
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c46e1e34",
      "metadata": {
        "id": "c46e1e34"
      },
      "outputs": [],
      "source": [
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
        "# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e859d6",
      "metadata": {
        "id": "83e859d6"
      },
      "outputs": [],
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3783ae9",
      "metadata": {
        "id": "b3783ae9"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "  target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "  target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  while not stop_condition:\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "    if (sampled_char == '\\n' or\n",
        "        len(decoded_sentence) > max_tar_len):\n",
        "        stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "873e8fbd",
      "metadata": {
        "scrolled": false,
        "id": "873e8fbd",
        "outputId": "3044a80c-1e4a-4517-c8c5-fa98004e5071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "입력 문장: 그 내용은 부품 사업자가 쉽게 알 수 없고 관여할 수 없기 때문에 중간 부품 생산자의 판매 행위는 대단히 불안한 지위에 놓이게 된다.\n",
            "정답 문장: Since the contents are not easily known and involved by the parts business operator, intermediate parts manufacturers' sales behavior is placed in a precarious position.\n",
            "\n",
            "번역 문장: The problem of a study is to examine the relationship between the two processes and the concept of a company and the concept of a construction of the concept of a construction of the concept of a construction of the concept of a construction of the concept of a constitution.\n",
            "-----------------------------------\n",
            "입력 문장: 먼저, 예제를 통해 정확한 목표 구역의 중요성을 살펴본다.\n",
            "정답 문장: First, the importance of accurate lot targeting is reviewed through an example.\n",
            "\n",
            "번역 문장: The problem of a study is to examine the relationship between the two processes and the concept of a company and the concept of a construction of the concept of a construction of the concept of a construction of the concept of a construction of the concept of a constitution.\n",
            "-----------------------------------\n",
            "입력 문장: AAA는 '취미' 개념을 인간의 마음이 '사고권'과 분리되지 않은 상태를 설명하기 위해 도입함으로써 그리스의 교육 이념으로 명명되었던 칼로카가티아의 의미를 현대적으로 재해석하고 있다는 느낌을 준다.\n",
            "정답 문장: By introducing the concept of “hobby” to explain the state in which the human mind is not separated from the “right to think,” AAA gives the impression that it is reinterpreting the meaning of Kalos kagathos, which was named as the Greek educational ideology, in a modern way.\n",
            "\n",
            "번역 문장: The problem of a study is to examine the relationship between the two processes and the concept of a company and the concept of a construction of the concept of a construction of the concept of a construction of the concept of a construction of the concept of a constitution.\n",
            "-----------------------------------\n",
            "입력 문장: 우리는 이제 쌍곡기하학에서 삼각형의 각도의 합계가 π가 되는지 안되는지 볼 수 있는 위치에 있다.\n",
            "정답 문장: We are now in a position to see whether the angles of a triangle in hyperbolic geometry add up to π or not.\n",
            "\n",
            "번역 문장: The problem of a study is to examine the relationship between the two processes and the concept of a company and the concept of a construction of the concept of a construction of the concept of a construction of the concept of a construction of the concept of a constitution.\n",
            "-----------------------------------\n",
            "입력 문장: 일에 대한 주관적인식에서 6개 하위변수 중 스스로 일을 통제하고자 하는 욕구를 제외한 모든 변수가 유의미한 영향을 미치는 것으로 나타났다.\n",
            "정답 문장: In the subjective perception of work, all variables except the desire to control work were found to have a significant effect among the six sub-variables.\n",
            "\n",
            "번역 문장: The problem of a study is to examine the relationship between the two processes and the concept of a company and the concept of a construction of the concept of a construction of the concept of a construction of the concept of a construction of the concept of a constitution.\n"
          ]
        }
      ],
      "source": [
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
        "  input_seq = encoder_input[seq_index:seq_index+1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장:', train_df.ko[seq_index])\n",
        "  print('정답 문장:', train_df.en[seq_index][2:len(train_df.en[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "  print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b4b4787",
      "metadata": {
        "id": "7b4b4787",
        "outputId": "948551ba-1793-4732-aad0-ab9852be3f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 1478)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 157)]  0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        1776640     ['input_1[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  423936      ['input_2[0][0]',                \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 157)    40349       ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,240,925\n",
            "Trainable params: 2,240,925\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a27082b9",
      "metadata": {
        "id": "a27082b9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4fc54e",
      "metadata": {
        "id": "7f4fc54e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Ai_09_전상언_Section4_Project_seq2seq.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}